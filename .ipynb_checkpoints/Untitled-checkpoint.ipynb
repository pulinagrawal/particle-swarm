{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-26c2606c12e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparam_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "x={'min':.5,'max':1}\n",
    "y={'min':1,'max':2}\n",
    "param_dict={1:x,2:y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print param_dict[1]['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(param_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OVERLOADABLE_OPERATORS',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array_priority__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__invert__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_add_consumer',\n",
       " '_as_node_def_input',\n",
       " '_override_operator',\n",
       " '_shape_as_list',\n",
       " 'consumers',\n",
       " 'device',\n",
       " 'dtype',\n",
       " 'eval',\n",
       " 'get_shape',\n",
       " 'graph',\n",
       " 'name',\n",
       " 'op',\n",
       " 'set_shape',\n",
       " 'value_index']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1.,2.],\n",
    "            [2.,2.],\n",
    "            [2.,1.]])\n",
    "c=np.array([2.,4.,6.])\n",
    "x=[1,2]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def shekel(x=1,y=2):\n",
    "    a=np.array([[1.,2.],\n",
    "                [2.,2.],\n",
    "                [2.,1.]])\n",
    "    c=np.array([2.,4.,6.])\n",
    "    print x,y\n",
    "    val=0\n",
    "    for i in xrange(len(c)):\n",
    "        val+=1./((x-a[i][0])**2.+(y-a[i][1])**2. + c[i])\n",
    "    return val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "0.55\n",
      "2 2\n",
      "0.72619047619\n",
      "1 2\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "l={'x':2,'y':3}\n",
    "l2=[2,2]\n",
    "print shekel(**l)\n",
    "print shekel(*l2)\n",
    "print shekel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.map_fn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 4.0], [3.0, 4.0], [5.0, 6.0]]\n",
      "Tensor(\"map/while/Squeeze:0\", shape=(), dtype=float32) Tensor(\"map/while/Squeeze_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"map/TensorArrayPack:0\", shape=(3,), dtype=float32)\n",
      "[ 0.34027779  0.27361113  0.08889452]\n"
     ]
    }
   ],
   "source": [
    "elems = [[1., 4.], [3., 4.], [5., 6.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "0.340277777778\n",
      "3 2\n",
      "0.491666666667\n"
     ]
    }
   ],
   "source": [
    "print shekel(*[1,4])\n",
    "print shekel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.random_uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-fd9b8decad0d>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-fd9b8decad0d>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    vel_update=tf.mul(tf.random_normal((1))*phi1,tf.sub(particle_best,particle_pos))\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def swarm(fitness_funct,particle_pos,particle_vel,phi1,phi2):\n",
    "    \n",
    "    particle_best=particle_pos.copy()\n",
    "        \n",
    "    def tf_fitness_funct_apply(l):\n",
    "        li=list()\n",
    "        for i in xrange(l.get_shape()[0]):\n",
    "            li.append(l[i])\n",
    "        return fitness_funct(*li)\n",
    "    tfff=tf_fitness_funct_apply\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        fitness_val=tf.map_fn(tfff,particle_pos)\n",
    "    \n",
    "    print(val)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      fitness=fitness_val.eval()\n",
    "    \n",
    "    particle_best_fitness=fitness.copy()\n",
    "    \n",
    "    # Now we have particle positions & fitness at this position,\n",
    "    #             particle velocities, \n",
    "    #             particle best postiion & particle fitness at that position\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        def distance(pos1,pos2):\n",
    "            return tf.pow(tf.reduce_sum(tf.pow(tf.sub(pos1,pos2),2)),.5)\n",
    "        \n",
    "        global_best=particle_pos[tf.arg_min(fitness)]\n",
    "        vel_local_update=tf.mul(tf.random_normal((1))*phi1,distance(particle_best,particle_pos))\n",
    "        vel_global_update=tf.mul(tf.random_normal((1))*phi2,distance(global_best,particle_pos))\n",
    "        vel_update=tf.add(vel_local_update,vel_global_update)\n",
    "        particle_vel= tf.add(particle_vel,vel_update)\n",
    "        particle_pos=tf.add(particle_pos,particle_vel)\n",
    "        fitness_val=tf.map_fn(tfff,particle_pos)\n",
    "        \n",
    "        # Fitness evaluated. Now need to update bests and calculate stopping criterion\n",
    "        \n",
    "    print(val)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      fitness=val.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swarm_complete(funct,param_dict,no_particles=25)\n",
    "\n",
    "    particles_vel=np.random.random(particles_pos.shape)\n",
    "    \n",
    "    for i in len(param_dict.keys()):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
